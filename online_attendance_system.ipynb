{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating objects to detect the face\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the data augmentation technique\n",
    "We make use of data augmentation technique to improve the quality of images and to increase the number of images in dataset. This data augmentation function returns 6 images with slight variation in all of them, thus to bring more versatality to the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from numpy import expand_dims\n",
    "def img_augment(img):\n",
    "    img_aug = []\n",
    "    datagen = ImageDataGenerator(horizontal_flip=True, rotation_range=45, \n",
    "                                 brightness_range=[0.2,1.5])\n",
    "    data = img_to_array(img)\n",
    "    # expand dimension to one sample\n",
    "    samples = expand_dims(data, 0)\n",
    "    # prepare iterator\n",
    "    it = datagen.flow(samples, batch_size=1)\n",
    "    # generate samples and plot\n",
    "    for i in range(5):\n",
    "        batch = it.next()\n",
    "        # convert to unsigned integers for viewing\n",
    "        image = batch[0].astype('uint8')\n",
    "        img_aug.append(image)\n",
    "    img_aug.append(img)\n",
    "    return img_aug\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dataset by capturing 300 face images of a subject\n",
    "If you don't have a prior dataset, you can use this piece of code to create your own dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "i = 0\n",
    "#fa_img = np.zeros((0,224,224,3),dtype=np.float32)\n",
    "while True:\n",
    "    if i == 300:\n",
    "        break\n",
    "    else:\n",
    "        \n",
    "        #read each frame of the video and convert it to gray\n",
    "        ret, img = cap.read()\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find faces in image using classifier\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "\n",
    "        # Draw rectangle around the faces\n",
    "        on = []\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255,255), 2)  \n",
    "            face_img = img[y:y + h, x:x + w]\n",
    "            face_img =  cv2.resize(face_img, (224,224), interpolation = cv2.INTER_AREA)\n",
    "            #fa_img[0,:,:,:] = face_img/223\n",
    "\n",
    "            cv2.imwrite(\"C:\\\\Users\\\\rajpu\\\\Desktop\\\\dataset\\\\face_dataset\\\\sahil%i.jpg\"%i, face_img)\n",
    "            font = cv2.FONT_HERSHEY_TRIPLEX\n",
    "            cv2.putText(img,'face',(x,y-2), font, 0.8, (0,255,255)) \n",
    "            i = i+1\n",
    "        #display image\n",
    "        cv2.imshow('img',img) \n",
    "\n",
    "        #if user pressed 'q' break\n",
    "        if cv2.waitKey(1) == ord('q'): # \n",
    "            break;\n",
    "\n",
    "cap.release() #turn off camera \n",
    "cv2.destroyAllWindows() #close all windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and preprocessing images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When dataset for different subjects is stored in different directories"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def detect_face(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Find faces in image using classifier\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.5, 5)\n",
    "    \n",
    "    # For every face found \n",
    "    if len(faces)==0:\n",
    "        return (0,img)\n",
    "    for (x,y,w,h) in faces:\n",
    "        face_img = img[y:y + h, x:x + w]\n",
    "    return (1,face_img)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "IMG_SHAPE = 224\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "indice = 0\n",
    "boolean = 1\n",
    "pa = 'C:\\\\Users\\\\rajpu\\\\Desktop\\\\dataset'\n",
    "for file_name in os.listdir(pa):\n",
    "\n",
    "    if file_name == 'abhi':\n",
    "        label = 0\n",
    "        path = \"\".join((pa,\"/\",file_name))\n",
    "        for j,i in enumerate(os.listdir(path)):\n",
    "            if i.endswith(\".jpg\") or i.endswith(\".jpeg\"):\n",
    "                img = cv2.imread(path+\"/\"+i)\n",
    "                boolean,img =  detect_face(img)\n",
    "                if boolean ==0:\n",
    "                    continue\n",
    "                # Resizing the image into required shape\n",
    "                img =  cv2.resize(img, (IMG_SHAPE,IMG_SHAPE), interpolation = cv2.INTER_AREA)\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "                indice = indice + 1\n",
    "\n",
    "    elif file_name == 'meet':\n",
    "        label = 1\n",
    "        path = \"\".join((pa,\"/\",file_name))\n",
    "        for j,i in enumerate(os.listdir(path)):\n",
    "            if i.endswith(\".jpg\") or i.endswith(\".jpeg\"):\n",
    "                img = cv2.imread(path+\"/\"+i)\n",
    "                boolean,img =  detect_face(img)\n",
    "                if boolean ==0:\n",
    "                    continue\n",
    "                # Resizing the image into required shape\n",
    "                img =  cv2.resize(img, (IMG_SHAPE,IMG_SHAPE), interpolation = cv2.INTER_AREA)\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "                indice = indice + 1\n",
    "\n",
    "    elif file_name == 'paras':\n",
    "        label = 2\n",
    "        path = \"\".join((pa,\"/\",file_name))\n",
    "        for j,i in enumerate(os.listdir(path)):\n",
    "            if i.endswith(\".jpg\") or i.endswith(\".jpeg\"):\n",
    "                img = cv2.imread(path+\"/\"+i)\n",
    "           \n",
    "                boolean,img =  detect_face(img)\n",
    "                if boolean ==0:\n",
    "                    continue\n",
    "                # Resizing the image into required shape\n",
    "                img =  cv2.resize(img, (IMG_SHAPE,IMG_SHAPE), interpolation = cv2.INTER_AREA)\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "                indice = indice + 1\n",
    "\n",
    "    elif file_name == 'prashant':\n",
    "        label = 3\n",
    "        path = \"\".join((pa,\"/\",file_name))\n",
    "        for j,i in enumerate(os.listdir(path)):\n",
    "            if i.endswith(\".jpg\") or i.endswith(\".jpeg\"):\n",
    "                img = cv2.imread(path+\"/\"+i)\n",
    "                boolean,img =  detect_face(img)\n",
    "                if boolean ==0:\n",
    "                    continue\n",
    "                # Resizing the image into required shape\n",
    "                img =  cv2.resize(img, (IMG_SHAPE,IMG_SHAPE), interpolation = cv2.INTER_AREA)\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "                indice = indice + 1\n",
    "\n",
    "    elif file_name == 'sahil':\n",
    "        label = 4\n",
    "        path = \"\".join((pa,\"/\",file_name))\n",
    "        for j,i in enumerate(os.listdir(path)):\n",
    "            if i.endswith(\".jpg\") or i.endswith(\".jpeg\"):\n",
    "                img = cv2.imread(path+\"/\"+i)\n",
    "                boolean,img =  detect_face(img)\n",
    "                if boolean ==0:\n",
    "                    continue\n",
    "                # Resizing the image into required shape\n",
    "                img =  cv2.resize(img, (IMG_SHAPE,IMG_SHAPE), interpolation = cv2.INTER_AREA)\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "                indice = indice + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When dataset stored in single directory\n",
    "Reading images when data from all subjects is stored in single directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function defined to read image data and resize it to (224,224)\n",
    "def pre_process(file_name, path):\n",
    "    IMG_SHAPE = 224\n",
    "    if file_name.endswith(\".jpg\") or file_name.endswith(\".jpeg\"):\n",
    "        img = cv2.imread(pa + \"\\\\\"+file_name)\n",
    "        img =  cv2.resize(img, (IMG_SHAPE,IMG_SHAPE), interpolation = cv2.INTER_AREA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading image dataset\n",
    "images = []\n",
    "labels = []\n",
    "indice = 0\n",
    "boolean = 1\n",
    "pa = 'C:\\\\Users\\\\rajpu\\\\Desktop\\\\dataset\\\\face_dataset'\n",
    "for file_name in os.listdir(pa):\n",
    "    if file_name.startswith(\"meet\"):\n",
    "        label = 0\n",
    "        img = pre_process(file_name, pa)\n",
    "    elif file_name.startswith(\"paras\"):\n",
    "        label = 1\n",
    "        img = pre_process(file_name, pa)\n",
    "    elif file_name.startswith(\"sahil\"):\n",
    "        label = 2\n",
    "        img = pre_process(file_name, pa)\n",
    "\n",
    "    images.append(img)\n",
    "    labels.append(label)\n",
    "    indice = indice + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "889it [00:46, 19.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# Calling the data augmentation function\n",
    "img = []\n",
    "X = []\n",
    "y = []\n",
    "for j,image in tqdm(enumerate(images)):\n",
    "    img = img_augment(image)\n",
    "    for i in img:\n",
    "        X.append(i)\n",
    "        y.append(labels[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping images\n",
    "IMG_SHAPE = 224\n",
    "n=len(X)\n",
    "\n",
    "data_images = np.zeros((n,IMG_SHAPE,IMG_SHAPE,3),dtype=np.float32)\n",
    "data_labels = np.zeros((n),dtype=np.float32)\n",
    "\n",
    "i = 0\n",
    "for item in range(len(X)):\n",
    "    data_images[i,:,:,:] = X[item]/223\n",
    "    data_labels[i] = y[item]\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test, y_train, y_test = train_test_split(data_images, data_labels, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Activation, UpSampling2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 109, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 52, 52, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 64)        73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                51264     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 237,093\n",
      "Trainable params: 237,093\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(5))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = keras.optimizers.Adam(lr=0.001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "768/768 [==============================] - 117s 150ms/step - loss: 0.6165 - accuracy: 0.7278 - val_loss: 0.1734 - val_accuracy: 0.9479\n",
      "Epoch 2/10\n",
      "768/768 [==============================] - 116s 152ms/step - loss: 0.1317 - accuracy: 0.9544 - val_loss: 0.0541 - val_accuracy: 0.9833\n",
      "Epoch 3/10\n",
      "768/768 [==============================] - 117s 153ms/step - loss: 0.0519 - accuracy: 0.9833 - val_loss: 0.0438 - val_accuracy: 0.9844\n",
      "Epoch 4/10\n",
      "768/768 [==============================] - 112s 146ms/step - loss: 0.0443 - accuracy: 0.9846 - val_loss: 0.0494 - val_accuracy: 0.9833\n",
      "Epoch 5/10\n",
      "768/768 [==============================] - 112s 146ms/step - loss: 0.0209 - accuracy: 0.9925 - val_loss: 0.0255 - val_accuracy: 0.9906\n",
      "Epoch 6/10\n",
      "768/768 [==============================] - 115s 149ms/step - loss: 0.0218 - accuracy: 0.9924 - val_loss: 0.0261 - val_accuracy: 0.9917\n",
      "Epoch 7/10\n",
      "768/768 [==============================] - 121s 157ms/step - loss: 0.0138 - accuracy: 0.9955 - val_loss: 0.0207 - val_accuracy: 0.9927\n",
      "Epoch 8/10\n",
      "768/768 [==============================] - 122s 159ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0971 - val_accuracy: 0.9750\n",
      "Epoch 9/10\n",
      "768/768 [==============================] - 123s 161ms/step - loss: 0.1081 - accuracy: 0.9748 - val_loss: 0.0136 - val_accuracy: 0.9927\n",
      "Epoch 10/10\n",
      "768/768 [==============================] - 125s 163ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.0130 - val_accuracy: 0.9937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18091288ec8>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=5, epochs=10, validation_split=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"C:\\\\Users\\\\rajpu\\\\Desktop\\\\dataset\\\\models\\\\model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test, batch_size = 5 )\n",
    "y_pred = list(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_output = []\n",
    "for i in range(len(y_pred)):\n",
    "    max_val = max(y_pred[i])\n",
    "    max_val_ind = list(y_pred[i]).index(max_val)\n",
    "    y_output.append(max_val_ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "534"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the faces in live video feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Online:  {'2021/9/14 11:58': ['Paras']}\n",
      "offline:  {'2021/9/14 11:58': ['Meet', 'Sahil']}\n",
      "Online:  {'2021/9/14 11:59': ['Paras']}\n",
      "offline:  {'2021/9/14 11:59': ['Meet', 'Sahil']}\n",
      "Online:  {'2021/9/14 11:59': ['Paras']}\n",
      "offline:  {'2021/9/14 11:59': ['Meet', 'Sahil']}\n",
      "Online:  {'2021/9/14 12:0': ['Paras']}\n",
      "offline:  {'2021/9/14 12:0': ['Meet', 'Sahil']}\n"
     ]
    }
   ],
   "source": [
    "# reading video and detecting people in it\n",
    "cap = cv2.VideoCapture(0)\n",
    "results = {0:'Meet', 1:'Paras', 2:'Sahil'}\n",
    "online = {}\n",
    "offline = {}\n",
    "max_val_ind = 0\n",
    "fa_img = np.zeros((n,224,224,3),dtype=np.float32)\n",
    "i = 1\n",
    "while True:\n",
    "    \n",
    "    #read each frame of the video and convert it to gray\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Find faces in image using classifier\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "   \n",
    "    # Draw rectangle around the faces\n",
    "    on = []\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255,255), 2)  \n",
    "        face_img = img[y:y + h, x:x + w]\n",
    "        face_img =  cv2.resize(face_img, (224,224), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "        fa_img[0,:,:,:] = face_img/223\n",
    "        if i%15 == 0:\n",
    "            y_pred = model.predict(fa_img)\n",
    "\n",
    "            max_val = max(y_pred[0])\n",
    "            max_val_ind = int(list(y_pred[0]).index(max_val))\n",
    "            font = cv2.FONT_HERSHEY_TRIPLEX\n",
    "            cv2.putText(img,results[max_val_ind],(x,y-2), font, 0.8, (0,255,255)) \n",
    "            on.append(results[max_val_ind])\n",
    "        #print(on)    \n",
    "            off = check_offline(on, results)\n",
    "            timestamp = get_timestamp()\n",
    "            online = {timestamp:on}\n",
    "            offline = {timestamp:off}\n",
    "            print(\"Online: \", online)\n",
    "            print(\"offline: \", offline)\n",
    "            #display image\n",
    "    i=i+1\n",
    "    cv2.imshow('img',img) \n",
    "\n",
    "    #if user pressed 'q' break\n",
    "    if cv2.waitKey(1) == ord('q'): # \n",
    "        break;\n",
    "\n",
    "cap.release() #turn off camera \n",
    "cv2.destroyAllWindows() #close all windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_offline(online, results):\n",
    "    if online == []:\n",
    "        return list(results.values())\n",
    "    ret = []\n",
    "    for item in results:\n",
    "        if results[item] not in online:\n",
    "            ret.append(results[item])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def get_timestamp():\n",
    "    dateTimeObj = datetime.now()\n",
    "    day = str(dateTimeObj.year)+ '/' + str(dateTimeObj.month) + '/' + str(dateTimeObj.day)\n",
    "    time = str(dateTimeObj.hour) + ':' + str(dateTimeObj.minute) \n",
    "    return (day + ' '+ time)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abhi', 'Meet', 'Paras', 'Prashant', 'Sahil']\n"
     ]
    }
   ],
   "source": [
    "print(list(results.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0,s1,s2,s3,s4 = 0,0,0,0,0\n",
    "for i in labels:\n",
    "    if i == 0:\n",
    "        s0 = s0+1\n",
    "    elif i == 1:\n",
    "        s1 = s1+1\n",
    "    elif i == 2:\n",
    "        s2 = s2+1\n",
    "    elif i == 3:\n",
    "        s3 = s3+1\n",
    "    else:\n",
    "        s4 = s4+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36   40   57   39   40\n"
     ]
    }
   ],
   "source": [
    "print(s0,\" \",s1,\" \", s2, \" \", s3, \" \", s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
